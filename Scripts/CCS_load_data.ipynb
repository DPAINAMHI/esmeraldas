{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.warp import Resampling\n",
    "from rasterio.crs import CRS\n",
    "from shapely.geometry import mapping\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.mask import mask\n",
    "import urllib.request\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def read_persiann_css_online0(url, nrow, ncol, dtype=np.int16):\n",
    "    \"\"\"Downloads, decompresses a Persiann CCS .bin.gz file, converts it to a NumPy array,\n",
    "        sets -9999 values to NaN, divides all values by 100, and reshapes to 2x2.\n",
    "\n",
    "        Args:\n",
    "            url: The URL of the Persiann CCS .bin.gz file.\n",
    "            dtype: The desired data type for the NumPy array (default: np.float32).\n",
    "\n",
    "        Returns:\n",
    "            A reshaped NumPy array containing the processed data as a nrow*ncol matrix.\n",
    "\n",
    "        Raises:\n",
    "            URLError: If an error occurs while downloading the file.\n",
    "            ValueError: If the decompressed data size is not compatible with nrow*ncol reshape.\n",
    "    \"\"\"\n",
    "    # Try opening the URL and decompressing the data\n",
    "    try:\n",
    "        compressed_data = requests.get(url).content\n",
    "        decompressed_data = gzip.decompress(compressed_data)\n",
    "        # Convert to NumPy array\n",
    "        data = np.frombuffer(decompressed_data, dtype=np.dtype('>h')).astype(float) \n",
    "        data = data.reshape((nrow,ncol))\n",
    "        data_1 = data[:,int(ncol/2):]\n",
    "        data_2 = data[:,:int(ncol/2)]\n",
    "        data = np.hstack((data_1,data_2))\n",
    "        data= data/100\n",
    "        data[data < 0] = np.nan\n",
    "        data = np.flipud(data)\n",
    "        print(f\"Data successfully downloaded from {url}\")\n",
    "        compressed_data = None\n",
    "        decompressed_data = None\n",
    "        data_1 = None\n",
    "        data_2 = None\n",
    "        del compressed_data\n",
    "        del decompressed_data\n",
    "        del data_1\n",
    "        del data_2\n",
    "        return data\n",
    "    except urllib.error.URLError as e:\n",
    "        raise urllib.error.URLError(f\"Error reading file from {url}: {e}\")\n",
    "\n",
    "\n",
    "def read_persiann_css_online(url, nrow, ncol):\n",
    "    \"\"\"Downloads, decompresses a Persiann CCS .bin.gz file, converts it to a NumPy array,\n",
    "       sets -9999 values to NaN, divides all values by 100, and reshapes to 2x2.\n",
    "       With visualized progress bar while downloading each file\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the Persiann CCS .bin.gz file.\n",
    "        nrow: Number of rows for reshaping the data.\n",
    "        ncol: Number of columns for reshaping the data.\n",
    "        dtype: The desired data type for the NumPy array (default: np.float32).\n",
    "\n",
    "    Returns:\n",
    "        A reshaped NumPy array containing the processed data as a nrow*ncol matrix.\n",
    "\n",
    "    Raises:\n",
    "        URLError: If an error occurs while downloading the file.\n",
    "        ValueError: If the decompressed data size is not compatible with nrow*ncol reshape.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Open the URL, handle unknown content length\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            total_size = int(response.headers.get('content-length', None))  # Get total size (if available)\n",
    "            progress_bar = tqdm(total=total_size, desc=\"Downloading data from \"+url, unit='B', unit_scale=True, unit_divisor=1024) if total_size is not None else tqdm(desc=\"Downloading data\")\n",
    "\n",
    "            # Alternative 1: Read data in chunks using read(chunksize)\n",
    "            compressed_data = b''\n",
    "            chunksize = 1024*100 # update per 100 kb of downloading\n",
    "            while True:\n",
    "                chunk = response.read(chunksize)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                compressed_data += chunk\n",
    "                if total_size is not None:  # Update progress if total size known\n",
    "                    progress_bar.update(len(chunk))\n",
    "\n",
    "            # Alternative 2: Read entire data (if content length is known or for small files)\n",
    "            # if total_size is not None:\n",
    "            #     compressed_data = response.read()\n",
    "\n",
    "            progress_bar.close()  # Close progress bar after download\n",
    "\n",
    "        # Decompress data\n",
    "        decompressed_data = gzip.decompress(compressed_data)\n",
    "        data = np.frombuffer(decompressed_data, dtype=np.dtype('>h')).astype(float) \n",
    "        data = data.reshape((nrow,ncol))\n",
    "        data_1 = data[:,int(ncol/2):]\n",
    "        data_2 = data[:,:int(ncol/2)]\n",
    "        data = np.hstack((data_1,data_2))\n",
    "        data= data/100\n",
    "        data = np.round(data,2)\n",
    "        data[data < 0] = np.nan\n",
    "        data = np.flipud(data)\n",
    "        return data\n",
    "    \n",
    "    except urllib.error.URLError as e:\n",
    "        raise urllib.error.URLError(f\"Error reading file from {url}: {e}\")\n",
    "\n",
    "def format_number_with_zeros(number, desired_digits):\n",
    "  \"\"\"Formats a number with leading zeros to reach the desired number of digits.\n",
    "\n",
    "  Args:\n",
    "      number: The integer to format.\n",
    "      desired_digits: The desired number of digits in the output string.\n",
    "\n",
    "  Returns:\n",
    "      A string representation of the number with leading zeros if needed.\n",
    "  \"\"\"\n",
    "\n",
    "  if not isinstance(number, int) or desired_digits <= 0:\n",
    "    raise ValueError(\"Invalid input: number must be an integer and desired_digits must be positive.\")\n",
    "\n",
    "  # Convert the number to a string\n",
    "  number_str = str(number)\n",
    "\n",
    "  # Add leading zeros if needed\n",
    "  num_leading_zeros = desired_digits - len(number_str)\n",
    "  formatted_string = \"0\" * num_leading_zeros + number_str\n",
    "\n",
    "  return formatted_string\n",
    "\n",
    "def iter_url(start_year, start_month, start_day, end_year, end_month, end_day, interval, max_num_of_obs_per_slice):\n",
    "    \"\"\"\n",
    "    Generates a set of URLs and corresponding date ranges based on the given parameters.\n",
    "\n",
    "    Args:\n",
    "        start_year: The starting year of the date range.\n",
    "        start_month: The starting month of the date range.\n",
    "        start_day: The starting day of the date range.\n",
    "        end_year: The ending year of the date range.\n",
    "        end_month: The ending month of the date range.\n",
    "        end_day: The ending day of the date range.\n",
    "        interval: The interval between URLs in hours (e.g., 3 for every 3 hours).\n",
    "        max_num_of_obs_per_slice: The maximum number of observations per data slice.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, each containing:\n",
    "        - urls: A list of generated URLs for the slice.\n",
    "        - date_slice: A pandas date range object representing the slice.\n",
    "        - start_datetime (pd.Timestamp): The start datetime of the slice.\n",
    "        - end_datetime (pd.Timestamp): The end datetime of the slice.\n",
    "        The number of observations in the given time range combining all slices\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the start and end time points\n",
    "    start_time = pd.Timestamp(year=start_year, month=start_month, day=start_day)\n",
    "    end_time = pd.Timestamp(year=end_year, month=end_month, day=end_day, hour=23,minute=59,second=59)\n",
    "    if start_time>end_time:\n",
    "       raise ValueError(\"start date must be no more recent than the end date inputed\")\n",
    "    # Construct the time range with the specified interval and inclusive \"left\" boundary\n",
    "    freq = str(interval) + 'h'\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq=freq, inclusive='left')\n",
    "    ranges = []\n",
    "    url_base = \"https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/\"\n",
    "\n",
    "    # Iterate over time slices\n",
    "    num_of_slice=math.ceil(len(time_range)/max_num_of_obs_per_slice)\n",
    "    for i in range(num_of_slice):\n",
    "        slice_start_index = i * max_num_of_obs_per_slice\n",
    "        slice_end_index = min((i + 1) * max_num_of_obs_per_slice - 1, len(time_range) - 1)  # Handle cases where the last slice might be shorter\n",
    "        slice_start = time_range[slice_start_index]\n",
    "        slice_end = time_range[slice_end_index]\n",
    "        date_slice = time_range[slice_start_index:slice_end_index + 1]  # Use direct slicing for DatetimeIndex\n",
    "        urls = []\n",
    "        # Iterate over all days within the slice\n",
    "        for time_point in date_slice:\n",
    "            doy = time_point.timetuple().tm_yday  # Day of the year\n",
    "            year_2d = str(time_point.year)[-2:]  # Last two digits of the year\n",
    "            doy_formatted = format_number_with_zeros(doy, 3)\n",
    "            hh_formatted = format_number_with_zeros(time_point.hour, 2)  # Hour with leading zeros\n",
    "            # Construct the URL\n",
    "            url = url_base + str(interval) + \"hrly/\" + \"rgccs\" + freq + year_2d + doy_formatted + hh_formatted + '.bin.gz'\n",
    "            urls.append(url)\n",
    "\n",
    "        range_dict = {\n",
    "            \"urls\": urls,\n",
    "            \"date_slice\": date_slice,\n",
    "            \"start_datetime\": slice_start,\n",
    "            \"end_datetime\": slice_end,\n",
    "        }\n",
    "        ranges.append(range_dict)\n",
    "\n",
    "    print(f\"{len(time_range)} datasets from {start_time.date()} to {end_time.date()} with a frequency of {freq} will be downloaded from {url_base}\")\n",
    "    return ranges, len(time_range)\n",
    "\n",
    "def num_to_ordinal(num):\n",
    "  \"\"\"\n",
    "  Converts a number to its ordinal representation.\n",
    "\n",
    "  Args:\n",
    "      num: The number to be converted (must be an integer).\n",
    "\n",
    "  Returns:\n",
    "      str: The ordinal representation of the number (e.g., \"1st\", \"2nd\", \"3rd\", etc.).\n",
    "\n",
    "  Raises:\n",
    "      ValueError: If the input number is not an integer.\n",
    "  \"\"\"\n",
    "\n",
    "  if not isinstance(num, int):\n",
    "    raise ValueError(\"Input must be an integer\")\n",
    "\n",
    "  # Handle special cases for numbers ending in 11, 12, and 13\n",
    "  if num % 100 in [11, 12, 13]:\n",
    "    return str(num) + \"th\"\n",
    "\n",
    "  # Get the last digit of the number\n",
    "  last_digit = num % 10\n",
    "\n",
    "  # Choose the appropriate suffix based on the last digit\n",
    "  suffix = \"st\" if last_digit == 1 else (\"nd\" if last_digit == 2 else (\"rd\" if last_digit == 3 else \"th\"))\n",
    "\n",
    "  return str(num) + suffix\n",
    "\n",
    "def download_geopackage(url, filename=\"temp.gpkg\"):\n",
    "  \"\"\"\n",
    "  Downloads a geopackage file from a URL.\n",
    "\n",
    "  Args:\n",
    "      url: The URL of the online geopackage file.\n",
    "      filename: Temporary filename to store the downloaded geopackage (optional).\n",
    "\n",
    "  Returns:\n",
    "      The filename of the downloaded geopackage.\n",
    "  \"\"\"\n",
    "  # Download the geopackage file\n",
    "  response = requests.get(url, stream=True)\n",
    "  if response.status_code == 200:\n",
    "    with open(filename, 'wb') as f:\n",
    "      for chunk in response.iter_content(1024):\n",
    "        f.write(chunk)\n",
    "    print(f\"Succeeded in downloading geopackage from {url}\")\n",
    "    del response\n",
    "    return filename\n",
    "  else:\n",
    "    raise ValueError(f\"Failed to download geopackage from {url}\")\n",
    "\n",
    "def clip_data(np_data, shape_esm):\n",
    "    \"\"\"\n",
    "    Clips the DataArray 'data' using the geometry from 'shape_esm'.\n",
    "\n",
    "    Args:\n",
    "        np_data (xr.DataArray): The DataArray to clip.\n",
    "        shape_esm (geopandas.GeoDataFrame): GeoDataFrame containing the geometry to clip with.\n",
    "\n",
    "    Returns:\n",
    "        xr.DataArray: The clipped DataArray.\n",
    "    \"\"\"\n",
    "\n",
    "    lat = np.arange(60, -60, -0.04)  # 3000 rows\n",
    "    lon = np.arange(-180, 180, 0.04)  # 9000 cols\n",
    "\n",
    "    data = xr.DataArray(data=np_data, dims=[\"lat\", \"lon\"], coords=[lat, lon])\n",
    "    data.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "    data.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "    data_esm = data.rio.clip(shape_esm.geometry.apply(mapping), shape_esm.crs, all_touched=True)\n",
    "    lat = None\n",
    "    lon = None\n",
    "    data = None\n",
    "    del lat\n",
    "    del lon\n",
    "    del data\n",
    "    return data_esm \n",
    "\n",
    "def clip_array_with_geopackage(data, filename, crs=None):\n",
    "  \"\"\"\n",
    "  Clips a NumPy array using a geopackage file.\n",
    "\n",
    "  Args:\n",
    "      data: The NumPy array to clip.\n",
    "      filename: Path to the geopackage file.\n",
    "      crs: Coordinate Reference System (CRS) of the data and shapefile (optional).\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array representing the clipped data.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the shapefile\n",
    "  gdf = gpd.read_file(filename)\n",
    "\n",
    "  # Get the first geometry (assuming only one shape is needed)\n",
    "  geometry = mapping(gdf.iloc[0].geometry)\n",
    "\n",
    "  # Open the raster dataset from the NumPy array\n",
    "  with rasterio.open(None, \"w\", driver=\"GTiff\", height=data.shape[0], width=data.shape[1], count=1, dtype=data.dtype) as src:\n",
    "    src.transform = rasterio.Affine.identity  # Assuming unit transform for simplicity\n",
    "    src.crs = crs if crs else CRS.from_epsg(4326)  # Default to EPSG:4326 (WGS84)\n",
    "    src.write(data, 1)\n",
    "\n",
    "    # Clip the raster by the geometry\n",
    "    clipped, transform = rasterio.rasterize(shapes=[geometry], out_shape=data.shape, fill=0, transform=src.transform, crs=src.crs, resampling=Resampling.nearest)\n",
    "\n",
    "  # Cleanup (optional, remove downloaded file after use)\n",
    "  # import os\n",
    "  # if os.path.exists(filename):\n",
    "  #   os.remove(filename)\n",
    "\n",
    "  return clipped\n",
    "\n",
    "def read_persiann_ccs(file_path):\n",
    "    ncols, nrows = 9000, 3000\n",
    "    data = np.zeros((nrows, ncols), dtype=np.float32)  # Initialize data array\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        for i in range(nrows):\n",
    "            for j in range(ncols):\n",
    "                # Read two bytes from the file, big-endian format\n",
    "                val = struct.unpack('>h', f.read(2))[0]\n",
    "                # Convert to mm/3hr, handling the no-data value\n",
    "                data[i, j] = np.nan if val == -9999 else val / 100.0\n",
    "\n",
    "    return data\n",
    "# return a numpy array\n",
    "def convert_to_geotiff(data, geotiff_path):\n",
    "    transform = from_origin(-180, 60, 0.04, 0.04)\n",
    "    metadata = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': data.shape[0],\n",
    "        'width': data.shape[1],\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'crs': '+proj=latlong',\n",
    "        'transform': transform\n",
    "    }\n",
    "    \n",
    "    with rasterio.open(geotiff_path, 'w', **metadata) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "def clip_raster_with_gpkg(raster_path, gpkg_path, clipped_raster_path):\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    gdf = gdf.to_crs(crs='+proj=latlong')\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = mask(src, gdf.geometry, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        \n",
    "        out_meta.update({\n",
    "            'driver': 'GTiff',\n",
    "            'height': out_image.shape[1],\n",
    "            'width': out_image.shape[2],\n",
    "            'transform': out_transform\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(clipped_raster_path, 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "# def plot_clipped_data(clipped_raster_path):\n",
    "#     with rasterio.open(clipped_raster_path) as src:\n",
    "#         data = src.read(1)\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.imshow(data, cmap='viridis', origin='upper')\n",
    "#         plt.colorbar(label='Precipitation (mm/3hr)')\n",
    "#         plt.title('Clipped PERSIANN-CCS Precipitation')\n",
    "#         plt.xlabel('Longitude')\n",
    "#         plt.ylabel('Latitude')\n",
    "#         plt.show()\n",
    "\n",
    "def plot_clipped_data(clipped_raster_array):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(clipped_raster_array, cmap='viridis', origin='upper')\n",
    "    plt.colorbar(label='Precipitation (mm/3hr)')\n",
    "    plt.title('Clipped PERSIANN-CCS Precipitation')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.show()\n",
    "\n",
    "# # Paths\n",
    "# file_path = \"C:/Users/liang.yang/Downloads/rgccs3h0300100.bin.gz\"\n",
    "# geotiff_path = '/home/hidrologia/Downloads/rgccs3h0300100.tif'\n",
    "# gpkg_path = '/home/hidrologia/Pronostico_hidro/Inputs/Manduriacu_delimitada.gpkg'\n",
    "# clipped_raster_path = '/home/hidrologia/Downloads/clipped_rgccs3h0300100.tif'\n",
    "\n",
    "# # Read and convert the data to GeoTIFF\n",
    "# data = read_persiann_ccs(file_path)\n",
    "# convert_to_geotiff(data, geotiff_path)\n",
    "\n",
    "# # Clip the GeoTIFF with the geopackage shapefile\n",
    "# clip_raster_with_gpkg(geotiff_path, gpkg_path, clipped_raster_path)\n",
    "\n",
    "# # Plot the clipped data\n",
    "# plot_clipped_data(clipped_raster_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded in downloading geopackage from https://github.com/DPAINAMHI/esmeraldas/raw/bba2fdfc0fa2098b99d9e106f4775cc42b56de8a/Basins/esmeraldas.gpkg\n",
      "3272 datasets from 2023-01-18 to 2024-03-01 with a frequency of 3h will be downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/\n",
      "\n",
      "***********************************************************\n",
      "Start to process the 1st slice, 817 slices left\n",
      "\n",
      "Start to download the 1st file of the 1st slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301800.bin.gz, 3 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301800.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T00:00:00.000000000 \n",
      "1 of 3272 downloaded\n",
      "Start to download the 2nd file of the 1st slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301803.bin.gz, 2 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301803.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T03:00:00.000000000 \n",
      "2 of 3272 downloaded\n",
      "Start to download the 3rd file of the 1st slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301806.bin.gz, 1 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301806.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T06:00:00.000000000 \n",
      "3 of 3272 downloaded\n",
      "Start to download the 4th file of the 1st slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301809.bin.gz, 0 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301809.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T09:00:00.000000000 \n",
      "4 of 3272 downloaded\n",
      "Clipped arrays from 20230118HH00 to 20230118HH09 saved to clipped_ds_3h\\20230118HH00__20230118HH09.nc\n",
      "This is the 1st file of 818 in total\n",
      "\n",
      "***********************************************************\n",
      "Start to process the 2nd slice, 816 slices left\n",
      "\n",
      "Start to download the 1st file of the 2nd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301812.bin.gz, 3 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301812.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T12:00:00.000000000 \n",
      "5 of 3272 downloaded\n",
      "Start to download the 2nd file of the 2nd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301815.bin.gz, 2 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301815.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T15:00:00.000000000 \n",
      "6 of 3272 downloaded\n",
      "Start to download the 3rd file of the 2nd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301818.bin.gz, 1 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301818.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T18:00:00.000000000 \n",
      "7 of 3272 downloaded\n",
      "Start to download the 4th file of the 2nd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301821.bin.gz, 0 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301821.bin.gz\n",
      "Succeeded in storing data of 2023-01-18T21:00:00.000000000 \n",
      "8 of 3272 downloaded\n",
      "Clipped arrays from 20230118HH12 to 20230118HH21 saved to clipped_ds_3h\\20230118HH12__20230118HH21.nc\n",
      "This is the 2nd file of 818 in total\n",
      "\n",
      "***********************************************************\n",
      "Start to process the 3rd slice, 815 slices left\n",
      "\n",
      "Start to download the 1st file of the 3rd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301900.bin.gz, 3 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301900.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T00:00:00.000000000 \n",
      "9 of 3272 downloaded\n",
      "Start to download the 2nd file of the 3rd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301903.bin.gz, 2 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301903.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T03:00:00.000000000 \n",
      "10 of 3272 downloaded\n",
      "Start to download the 3rd file of the 3rd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301906.bin.gz, 1 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301906.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T06:00:00.000000000 \n",
      "11 of 3272 downloaded\n",
      "Start to download the 4th file of the 3rd slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301909.bin.gz, 0 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301909.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T09:00:00.000000000 \n",
      "12 of 3272 downloaded\n",
      "Clipped arrays from 20230119HH00 to 20230119HH09 saved to clipped_ds_3h\\20230119HH00__20230119HH09.nc\n",
      "This is the 3rd file of 818 in total\n",
      "\n",
      "***********************************************************\n",
      "Start to process the 4th slice, 814 slices left\n",
      "\n",
      "Start to download the 1st file of the 4th slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301912.bin.gz, 3 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301912.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T12:00:00.000000000 \n",
      "13 of 3272 downloaded\n",
      "Start to download the 2nd file of the 4th slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301915.bin.gz, 2 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301915.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T15:00:00.000000000 \n",
      "14 of 3272 downloaded\n",
      "Start to download the 3rd file of the 4th slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301918.bin.gz, 1 files left in this slice\n",
      "Data successfully downloaded from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301918.bin.gz\n",
      "Succeeded in storing data of 2023-01-19T18:00:00.000000000 \n",
      "15 of 3272 downloaded\n",
      "Start to download the 4th file of the 4th slice from https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2301921.bin.gz, 0 files left in this slice\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to download the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_to_ordinal(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_to_ordinal(t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m slice from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_obs_per_slice\u001b[38;5;241m-\u001b[39mi\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files left in this slice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m     array_esm_temp \u001b[38;5;241m=\u001b[39m clip_data(\u001b[43mread_persiann_css_online0\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncol\u001b[49m\u001b[43m)\u001b[49m, shape_file)\n\u001b[0;32m     31\u001b[0m     t_downloaded\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m     array_list\u001b[38;5;241m.\u001b[39mappend(array_esm_temp)\n",
      "Cell \u001b[1;32mIn[120], line 44\u001b[0m, in \u001b[0;36mread_persiann_css_online0\u001b[1;34m(url, nrow, ncol, dtype)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Try opening the URL and decompressing the data\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     compressed_data \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     45\u001b[0m     decompressed_data \u001b[38;5;241m=\u001b[39m gzip\u001b[38;5;241m.\u001b[39mdecompress(compressed_data)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Convert to NumPy array\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\urllib3\\response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1043\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1046\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\urllib3\\response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 935\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\urllib3\\response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 862\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\site-packages\\urllib3\\response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\liang.yang\\AppData\\Local\\anaconda3\\envs\\py3.10\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nrow = 3000\n",
    "ncol = 9000 # As per the readme file of the raw dataset\n",
    "start_year=2023\n",
    "start_month=1\n",
    "start_day=18\n",
    "end_year=2024\n",
    "end_month=3\n",
    "end_day=1\n",
    "interval=3 # choose from 3 and 6\n",
    "shape_file_url = \"https://github.com/DPAINAMHI/esmeraldas/raw/bba2fdfc0fa2098b99d9e106f4775cc42b56de8a/Basins/esmeraldas.gpkg\"\n",
    "max_obs_per_slice=4\n",
    "# Download the shape file of Esmeraldas from the github repo\n",
    "shape_file = download_geopackage(shape_file_url)\n",
    "shape_file=gpd.read_file(shape_file)\n",
    "\n",
    "# Get the list of URLs and desired time range of data\n",
    "slice_list, num_of_obs = iter_url(start_year,start_month,start_day,end_year,end_month,end_day,interval,max_obs_per_slice)\n",
    "t_downloaded=0\n",
    "for t, slice in enumerate(slice_list):\n",
    "\n",
    "    print(\"\\n***********************************************************\")\n",
    "    print(f\"Start to process the {num_to_ordinal(t+1)} slice, {len(slice_list)-t-1} slices left\\n\")\n",
    "    \n",
    "    time_range = xr.DataArray(dims='time',data=slice['date_slice'])\n",
    "    \n",
    "    array_list=[] # Null container of all the clipped array\n",
    "    for i, url in enumerate(slice['urls']):\n",
    "        try:\n",
    "            print(f\"Start to download the {num_to_ordinal(i+1)} file of the {num_to_ordinal(t+1)} slice from {url}, {max_obs_per_slice-i-1} files left in this slice\")\n",
    "            array_esm_temp = clip_data(read_persiann_css_online0(url, nrow, ncol), shape_file)\n",
    "            t_downloaded+=1\n",
    "            array_list.append(array_esm_temp)\n",
    "            array_esm_temp = None\n",
    "            del array_esm_temp\n",
    "            del url\n",
    "            print(f\"Succeeded in storing data of {time_range[i].data} \\n{t_downloaded} of {num_of_obs} downloaded\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL {url}: {e}\")    \n",
    "            time_range = time_range.drop_isel({\"time\":i}) \n",
    "    dataset = xr.concat(array_list, dim=time_range.variable)\n",
    "    dataset = dataset.drop_vars('spatial_ref')\n",
    "    data_dict = {\"precipitation\": dataset}\n",
    "    ds = xr.Dataset(data_dict)\n",
    "    ds = ds.astype(np.float32)\n",
    "    dataset = None\n",
    "    data_dict = None\n",
    "    del dataset\n",
    "    del data_dict\n",
    "    slice_start = str(slice['start_datetime'].date())+\"HH\"+format_number_with_zeros(slice['start_datetime'].hour,2)\n",
    "    slice_start = slice_start.replace('-','')\n",
    "    slice_end = str(slice['end_datetime'].date())+\"HH\"+format_number_with_zeros(slice['end_datetime'].hour,2)\n",
    "    slice_end = slice_end.replace('-','')\n",
    "    dest_folder_name = \"clipped_ds_\"+str(interval)+'h'\n",
    "    # Check if the new folder exists\n",
    "    if not os.path.exists(dest_folder_name):\n",
    "        # Create the new folder if it already exists in the current work dir\n",
    "        os.makedirs(dest_folder_name)\n",
    "    # Define the filename for the dataset\n",
    "    output_filename = slice_start + '__' + slice_end +'.nc'\n",
    "    # Combine the folder path and filename\n",
    "    full_path = os.path.join(dest_folder_name, output_filename)\n",
    "    ds.to_netcdf(full_path)\n",
    "    ds = None\n",
    "    del ds\n",
    "    slice = None\n",
    "    del slice\n",
    "    array_list = None\n",
    "    del array_list\n",
    "    time_range = None\n",
    "    del time_range\n",
    "    print(f\"Clipped arrays from {slice_start} to {slice_end} saved to {full_path}\")\n",
    "    print(f\"This is the {num_to_ordinal(t+1)} file of {len(slice_list)} in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('clipped_ds_6h/20230101HH00__20230101HH00.nc')\n",
    "a=ds.precipitation[0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(ds.precipitation.argmax(...)) # Method for conditional selecting\n",
    "ds.precipitation[0].data # Method for slicing or indexing, never use .values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(time_range)\n",
    "v = da.variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (time: 2)&gt; Size: 16B\n",
       "array([&#x27;2023-01-18T00:00:00.000000000&#x27;, &#x27;2023-01-18T09:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 16B 2023-01-18 2023-01-18T09:00:00</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 2</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-d69b3db2-aadd-45c1-812d-7098b52f4e74' class='xr-array-in' type='checkbox' checked><label for='section-d69b3db2-aadd-45c1-812d-7098b52f4e74' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>2023-01-18 2023-01-18T09:00:00</span></div><div class='xr-array-data'><pre>array([&#x27;2023-01-18T00:00:00.000000000&#x27;, &#x27;2023-01-18T09:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></div></li><li class='xr-section-item'><input id='section-ddddc24f-bf0a-47ca-b041-1a46e165939b' class='xr-section-summary-in' type='checkbox'  checked><label for='section-ddddc24f-bf0a-47ca-b041-1a46e165939b' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2023-01-18 2023-01-18T09:00:00</div><input id='attrs-16ced38c-0de8-4379-a23e-661addaa9e60' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-16ced38c-0de8-4379-a23e-661addaa9e60' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d6374d05-bc86-48b3-9fd3-03f901a05d54' class='xr-var-data-in' type='checkbox'><label for='data-d6374d05-bc86-48b3-9fd3-03f901a05d54' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2023-01-18T00:00:00.000000000&#x27;, &#x27;2023-01-18T09:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8c6167eb-5816-4164-b166-81e99e0ed7d8' class='xr-section-summary-in' type='checkbox'  ><label for='section-8c6167eb-5816-4164-b166-81e99e0ed7d8' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-4eb7db38-7e09-4e17-9910-8ac7193a1be0' class='xr-index-data-in' type='checkbox'/><label for='index-4eb7db38-7e09-4e17-9910-8ac7193a1be0' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2023-01-18 00:00:00&#x27;, &#x27;2023-01-18 09:00:00&#x27;], dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6fb1a685-13f8-4c31-86be-98d337fc8684' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-6fb1a685-13f8-4c31-86be-98d337fc8684' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (time: 2)> Size: 16B\n",
       "array(['2023-01-18T00:00:00.000000000', '2023-01-18T09:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 16B 2023-01-18 2023-01-18T09:00:00"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Variable (time: 128)&gt; Size: 1kB\n",
       "array([&#x27;2023-01-18T00:00:00.000000000&#x27;, &#x27;2023-01-18T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T06:00:00.000000000&#x27;, &#x27;2023-01-18T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T12:00:00.000000000&#x27;, &#x27;2023-01-18T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T18:00:00.000000000&#x27;, &#x27;2023-01-18T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T00:00:00.000000000&#x27;, &#x27;2023-01-19T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T06:00:00.000000000&#x27;, &#x27;2023-01-19T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T12:00:00.000000000&#x27;, &#x27;2023-01-19T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T18:00:00.000000000&#x27;, &#x27;2023-01-19T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T00:00:00.000000000&#x27;, &#x27;2023-01-20T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T06:00:00.000000000&#x27;, &#x27;2023-01-20T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T12:00:00.000000000&#x27;, &#x27;2023-01-20T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T18:00:00.000000000&#x27;, &#x27;2023-01-20T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T00:00:00.000000000&#x27;, &#x27;2023-01-21T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T06:00:00.000000000&#x27;, &#x27;2023-01-21T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T12:00:00.000000000&#x27;, &#x27;2023-01-21T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T18:00:00.000000000&#x27;, &#x27;2023-01-21T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T00:00:00.000000000&#x27;, &#x27;2023-01-22T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T06:00:00.000000000&#x27;, &#x27;2023-01-22T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T12:00:00.000000000&#x27;, &#x27;2023-01-22T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T18:00:00.000000000&#x27;, &#x27;2023-01-22T21:00:00.000000000&#x27;,\n",
       "...\n",
       "       &#x27;2023-01-29T06:00:00.000000000&#x27;, &#x27;2023-01-29T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-29T12:00:00.000000000&#x27;, &#x27;2023-01-29T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-29T18:00:00.000000000&#x27;, &#x27;2023-01-29T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T00:00:00.000000000&#x27;, &#x27;2023-01-30T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T06:00:00.000000000&#x27;, &#x27;2023-01-30T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T12:00:00.000000000&#x27;, &#x27;2023-01-30T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T18:00:00.000000000&#x27;, &#x27;2023-01-30T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T00:00:00.000000000&#x27;, &#x27;2023-01-31T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T06:00:00.000000000&#x27;, &#x27;2023-01-31T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T12:00:00.000000000&#x27;, &#x27;2023-01-31T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T18:00:00.000000000&#x27;, &#x27;2023-01-31T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T00:00:00.000000000&#x27;, &#x27;2023-02-01T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T06:00:00.000000000&#x27;, &#x27;2023-02-01T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T12:00:00.000000000&#x27;, &#x27;2023-02-01T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T18:00:00.000000000&#x27;, &#x27;2023-02-01T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T00:00:00.000000000&#x27;, &#x27;2023-02-02T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T06:00:00.000000000&#x27;, &#x27;2023-02-02T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T12:00:00.000000000&#x27;, &#x27;2023-02-02T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T18:00:00.000000000&#x27;, &#x27;2023-02-02T21:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Variable</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span>time</span>: 128</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-330e6d27-86ec-4f67-b8b9-c82cad8007df' class='xr-array-in' type='checkbox' checked><label for='section-330e6d27-86ec-4f67-b8b9-c82cad8007df' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>2023-01-18 2023-01-18T03:00:00 ... 2023-02-02T21:00:00</span></div><div class='xr-array-data'><pre>array([&#x27;2023-01-18T00:00:00.000000000&#x27;, &#x27;2023-01-18T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T06:00:00.000000000&#x27;, &#x27;2023-01-18T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T12:00:00.000000000&#x27;, &#x27;2023-01-18T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-18T18:00:00.000000000&#x27;, &#x27;2023-01-18T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T00:00:00.000000000&#x27;, &#x27;2023-01-19T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T06:00:00.000000000&#x27;, &#x27;2023-01-19T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T12:00:00.000000000&#x27;, &#x27;2023-01-19T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-19T18:00:00.000000000&#x27;, &#x27;2023-01-19T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T00:00:00.000000000&#x27;, &#x27;2023-01-20T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T06:00:00.000000000&#x27;, &#x27;2023-01-20T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T12:00:00.000000000&#x27;, &#x27;2023-01-20T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-20T18:00:00.000000000&#x27;, &#x27;2023-01-20T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T00:00:00.000000000&#x27;, &#x27;2023-01-21T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T06:00:00.000000000&#x27;, &#x27;2023-01-21T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T12:00:00.000000000&#x27;, &#x27;2023-01-21T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-21T18:00:00.000000000&#x27;, &#x27;2023-01-21T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T00:00:00.000000000&#x27;, &#x27;2023-01-22T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T06:00:00.000000000&#x27;, &#x27;2023-01-22T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T12:00:00.000000000&#x27;, &#x27;2023-01-22T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-22T18:00:00.000000000&#x27;, &#x27;2023-01-22T21:00:00.000000000&#x27;,\n",
       "...\n",
       "       &#x27;2023-01-29T06:00:00.000000000&#x27;, &#x27;2023-01-29T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-29T12:00:00.000000000&#x27;, &#x27;2023-01-29T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-29T18:00:00.000000000&#x27;, &#x27;2023-01-29T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T00:00:00.000000000&#x27;, &#x27;2023-01-30T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T06:00:00.000000000&#x27;, &#x27;2023-01-30T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T12:00:00.000000000&#x27;, &#x27;2023-01-30T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-30T18:00:00.000000000&#x27;, &#x27;2023-01-30T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T00:00:00.000000000&#x27;, &#x27;2023-01-31T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T06:00:00.000000000&#x27;, &#x27;2023-01-31T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T12:00:00.000000000&#x27;, &#x27;2023-01-31T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-01-31T18:00:00.000000000&#x27;, &#x27;2023-01-31T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T00:00:00.000000000&#x27;, &#x27;2023-02-01T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T06:00:00.000000000&#x27;, &#x27;2023-02-01T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T12:00:00.000000000&#x27;, &#x27;2023-02-01T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-01T18:00:00.000000000&#x27;, &#x27;2023-02-01T21:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T00:00:00.000000000&#x27;, &#x27;2023-02-02T03:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T06:00:00.000000000&#x27;, &#x27;2023-02-02T09:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T12:00:00.000000000&#x27;, &#x27;2023-02-02T15:00:00.000000000&#x27;,\n",
       "       &#x27;2023-02-02T18:00:00.000000000&#x27;, &#x27;2023-02-02T21:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></div></li><li class='xr-section-item'><input id='section-1dd60e59-2600-4b38-b96d-ae67dbf39626' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-1dd60e59-2600-4b38-b96d-ae67dbf39626' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Variable (time: 128)> Size: 1kB\n",
       "array(['2023-01-18T00:00:00.000000000', '2023-01-18T03:00:00.000000000',\n",
       "       '2023-01-18T06:00:00.000000000', '2023-01-18T09:00:00.000000000',\n",
       "       '2023-01-18T12:00:00.000000000', '2023-01-18T15:00:00.000000000',\n",
       "       '2023-01-18T18:00:00.000000000', '2023-01-18T21:00:00.000000000',\n",
       "       '2023-01-19T00:00:00.000000000', '2023-01-19T03:00:00.000000000',\n",
       "       '2023-01-19T06:00:00.000000000', '2023-01-19T09:00:00.000000000',\n",
       "       '2023-01-19T12:00:00.000000000', '2023-01-19T15:00:00.000000000',\n",
       "       '2023-01-19T18:00:00.000000000', '2023-01-19T21:00:00.000000000',\n",
       "       '2023-01-20T00:00:00.000000000', '2023-01-20T03:00:00.000000000',\n",
       "       '2023-01-20T06:00:00.000000000', '2023-01-20T09:00:00.000000000',\n",
       "       '2023-01-20T12:00:00.000000000', '2023-01-20T15:00:00.000000000',\n",
       "       '2023-01-20T18:00:00.000000000', '2023-01-20T21:00:00.000000000',\n",
       "       '2023-01-21T00:00:00.000000000', '2023-01-21T03:00:00.000000000',\n",
       "       '2023-01-21T06:00:00.000000000', '2023-01-21T09:00:00.000000000',\n",
       "       '2023-01-21T12:00:00.000000000', '2023-01-21T15:00:00.000000000',\n",
       "       '2023-01-21T18:00:00.000000000', '2023-01-21T21:00:00.000000000',\n",
       "       '2023-01-22T00:00:00.000000000', '2023-01-22T03:00:00.000000000',\n",
       "       '2023-01-22T06:00:00.000000000', '2023-01-22T09:00:00.000000000',\n",
       "       '2023-01-22T12:00:00.000000000', '2023-01-22T15:00:00.000000000',\n",
       "       '2023-01-22T18:00:00.000000000', '2023-01-22T21:00:00.000000000',\n",
       "...\n",
       "       '2023-01-29T06:00:00.000000000', '2023-01-29T09:00:00.000000000',\n",
       "       '2023-01-29T12:00:00.000000000', '2023-01-29T15:00:00.000000000',\n",
       "       '2023-01-29T18:00:00.000000000', '2023-01-29T21:00:00.000000000',\n",
       "       '2023-01-30T00:00:00.000000000', '2023-01-30T03:00:00.000000000',\n",
       "       '2023-01-30T06:00:00.000000000', '2023-01-30T09:00:00.000000000',\n",
       "       '2023-01-30T12:00:00.000000000', '2023-01-30T15:00:00.000000000',\n",
       "       '2023-01-30T18:00:00.000000000', '2023-01-30T21:00:00.000000000',\n",
       "       '2023-01-31T00:00:00.000000000', '2023-01-31T03:00:00.000000000',\n",
       "       '2023-01-31T06:00:00.000000000', '2023-01-31T09:00:00.000000000',\n",
       "       '2023-01-31T12:00:00.000000000', '2023-01-31T15:00:00.000000000',\n",
       "       '2023-01-31T18:00:00.000000000', '2023-01-31T21:00:00.000000000',\n",
       "       '2023-02-01T00:00:00.000000000', '2023-02-01T03:00:00.000000000',\n",
       "       '2023-02-01T06:00:00.000000000', '2023-02-01T09:00:00.000000000',\n",
       "       '2023-02-01T12:00:00.000000000', '2023-02-01T15:00:00.000000000',\n",
       "       '2023-02-01T18:00:00.000000000', '2023-02-01T21:00:00.000000000',\n",
       "       '2023-02-02T00:00:00.000000000', '2023-02-02T03:00:00.000000000',\n",
       "       '2023-02-02T06:00:00.000000000', '2023-02-02T09:00:00.000000000',\n",
       "       '2023-02-02T12:00:00.000000000', '2023-02-02T15:00:00.000000000',\n",
       "       '2023-02-02T18:00:00.000000000', '2023-02-02T21:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da=xr.DataArray(dims='time',data=time_range.data)\n",
    "da.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'data' (x: 3, y: 4)> Size: 48B\n",
      "array([[ 0,  1,  2,  3],\n",
      "       [ 4,  5,  6,  7],\n",
      "       [ 8,  9, 10, 11]])\n",
      "Dimensions without coordinates: x, y\n",
      "<xarray.DataArray 'data' (x: 2, y: 4)> Size: 32B\n",
      "array([[0, 1, 2, 3],\n",
      "       [4, 5, 6, 7]])\n",
      "Dimensions without coordinates: x, y\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Sample data\n",
    "data = np.arange(12).reshape(3, 4)\n",
    "da = xr.DataArray(data, dims=(\"x\", \"y\"), name=\"data\")\n",
    "print(da)\n",
    "\n",
    "# Define the index and dimension to drop along\n",
    "index_to_remove = 2  # Index to remove\n",
    "dim_to_drop = 'x'  # Dimension along which to drop (can be 'y' or other dimensions)\n",
    "\n",
    "# Drop the element using drop_sel\n",
    "da_new = da.drop_sel({dim_to_drop: index_to_remove})\n",
    "\n",
    "print(da_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=np.arange(60,-60,-0.04) # 3000 rows\n",
    "lon=np.arange(-180,180,0.04) # 9000 cols\n",
    "data = xr.DataArray(data=data, dims=[\"lat\", \"lon\"], coords=[lat,lon])\n",
    "data.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "data.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "data_esm = data.rio.clip(shape_esm.geometry.apply(mapping),shape_esm.crs,all_touched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.subplots(figsize=(8,8))\n",
    "plt.imshow(clipped,cmap='cividis',vmin=0.1,vmax=12)\n",
    "plt.title(\"Precipitación Esmeraldas PERSIANN-CCS\")\n",
    "plt.colorbar(label='Precipitación (mm)')\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_css_local0(item):\n",
    "    f = gzip.GzipFile(item) # item is the local dic of the .bin.gz file\n",
    "    file_content = f.read()\n",
    "    data = np.frombuffer(file_content, dtype=np.dtype('>h')).astype(float) \n",
    "    data = data.reshape((3000,9000))\n",
    "    data_1 = data[:,4500:]\n",
    "    data_2 = data[:,:4500]\n",
    "    data = np.hstack((data_1,data_2))\n",
    "    data= data/100\n",
    "    data[data < 0] = np.nan\n",
    "    data = np.flipud(data)\n",
    "    return data\n",
    "\n",
    "def read_persiann_css_online1(url, nrow, ncol):\n",
    "    try:\n",
    "        decompressed_data = gzip.decompress(requests.get(url).content)\n",
    "        # Convert to NumPy array\n",
    "        data = np.frombuffer(decompressed_data, dtype=np.dtype('>h')).astype(float) \n",
    "        data = data.reshape((3000,9000))\n",
    "        data_1 = data[:,4500:]\n",
    "        data_2 = data[:,:4500]\n",
    "        data = np.hstack((data_1,data_2))\n",
    "        data= data/100\n",
    "        data[data < 0] = np.nan\n",
    "        data = np.flipud(data)\n",
    "        print(f\"Data successfully downloaded from {url}\")\n",
    "        return data\n",
    "    except urllib.error.URLError as e:\n",
    "        raise urllib.error.URLError(f\"Error reading file from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = \"C:/Users/liang.yang/Downloads/rgccs6h2300100.bin.gz\"\n",
    "shape_esm=gpd.read_file('C:/Users/liang.yang/Desktop/esmeraldas/Basins/esmeraldas.gpkg')\n",
    "d1=read_css_local0(item)\n",
    "lat=np.arange(60,-60,-0.04) # 3000 rows\n",
    "lon=np.arange(-180,180,0.04) # 9000 cols\n",
    "data = xr.DataArray(data=d1, dims=[\"lat\", \"lon\"], coords=[lat,lon])\n",
    "data.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "data.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "data_esm_1 = data.rio.clip(shape_esm.geometry.apply(mapping),shape_esm.crs,all_touched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "# URL of the .bin.gz file\n",
    "url = 'https://persiann.eng.uci.edu/CHRSdata/PERSIANN-CCS/3hrly/rgccs3h2300100.bin.gz'\n",
    "\n",
    "decompressed_data = gzip.decompress(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "data = np.frombuffer(decompressed_data, dtype=np.dtype('>h')).astype(float) \n",
    "data = data.reshape((3000,9000))\n",
    "data_1 = data[:,4500:]\n",
    "data_2 = data[:,:4500]\n",
    "data = np.hstack((data_1,data_2))\n",
    "data= data/100\n",
    "data[data < 0] = np.nan\n",
    "data = np.flipud(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the decompressed data to a NumPy array\n",
    "\n",
    "clipped_online=clip_data(data,shape_esm)\n",
    "clipped_online=clipped_online.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
