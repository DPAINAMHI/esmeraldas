{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funct\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import IPython\n",
    "import netCDF4 as nc\n",
    "import  xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read historical CCS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incomplete data of June, 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 3\n",
    "rela_path_base = \"Data\\Persian_CCS_201901_202403\\CCS_esmJSON_2024-03-08075032am_\"\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    "    )\n",
    "# Get the parent directory path\n",
    "parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "# Change the directory (optional)\n",
    "os.chdir(parent_dir)\n",
    "# Now, your current working directory is the parent folder.\n",
    "\n",
    "df_list = []\n",
    "first_iter = True\n",
    "for month in funct.iterate_months(2019, 1, 2024, 3):\n",
    "    rela_path = rela_path_base + month + \".nc\"\n",
    "    df = funct.create_time_series_dataframe(freq, rela_path)\n",
    "    if first_iter:\n",
    "        df = df.replace(-99,np.nan)\n",
    "        cols_after_drop = df.dropna(axis=1, how='any').columns\n",
    "        first_iter = False\n",
    "    df_dropped = df[[col for col in cols_after_drop]]\n",
    "    df_list.append(df_dropped)\n",
    "df_ccs = pd.concat(df_list)\n",
    "# orginal shape of the Esmeraldas basin is of size 53*52\n",
    "# New flat array of 1098 pixels, showing only the net pixels of this basin area "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and organize data from Esmeraldas station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-01 ['N Sens' '78652']\n",
      "2023-10-02 ['N Sens' '78652']\n",
      "2023-10-03 ['N Sens' '78652']\n",
      "2023-10-04 ['N Sens' '78652']\n",
      "2023-10-05 ['N Sens' '78652']\n",
      "2023-10-06 ['N Sens' '78652']\n",
      "2023-10-12 ['N Sens' '78652']\n",
      "2023-10-13 ['N Sens' '78652']\n",
      "2023-10-14 ['N Sens' '78652']\n",
      "2023-10-15 ['N Sens' '78652']\n",
      "2023-10-16 ['N Sens' '78652']\n",
      "2023-10-17 ['N Sens' '78652']\n",
      "2023-10-18 ['N Sens' '78652']\n",
      "2023-10-19 ['N Sens' '78652']\n",
      "2023-10-20 ['N Sens' '78652']\n",
      "2023-10-21 ['N Sens' '78652']\n",
      "2023-10-22 ['N Sens' '78652']\n",
      "2023-10-23 ['N Sens' '78652']\n",
      "2023-10-24 ['N Sens' '78652']\n"
     ]
    }
   ],
   "source": [
    "funct = importlib.reload(funct)\n",
    "from datetime import date, timedelta, datetime\n",
    "from funct import format_number_with_zeros, diff, mmean\n",
    "import chardet\n",
    "import re\n",
    "\n",
    "# Define start and end dates (replace with your desired dates)\n",
    "start_date = date(2023, 9, 6)  # Adjust year, month, day as needed\n",
    "end_date = date(2024, 3, 8)  # Adjust year, month, day as needed\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    "    )\n",
    "# Get the parent directory path\n",
    "parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "# Change the directory (optional)\n",
    "os.chdir(parent_dir)\n",
    "# Now, your current working directory is the parent folder.\n",
    "\n",
    "# Iterate through each day using a for loop and timedelta\n",
    "\n",
    "df_list_esm = []\n",
    "df_list_esm_err = []\n",
    "\n",
    "# iterate to read every .csv file and convert them into transposed dataframe to align with the form of ccs data\n",
    "for day in range((end_date - start_date).days + 1):\n",
    "    current_date = start_date + timedelta(days=day)\n",
    "    # Do something with the current_date here (e.g., print, process data)\n",
    "    year = current_date.year\n",
    "    month = format_number_with_zeros(current_date.month,2)\n",
    "    day = format_number_with_zeros(current_date.day,2)\n",
    "    csv_path = \"Data\\Esm_Station\\yd\" + str(year) + \"\\md\" + str(year) + str(month) + \"\\\\\" + str(year) + str(month) + str(day) + \"_dvd.csv\"\n",
    "    with open(csv_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding']\n",
    "    df = pd.read_csv(csv_path, encoding= encoding, header = None ,skiprows=2)\n",
    "    df = df[0].apply(lambda x: pd.Series(re.split(';', x)))\n",
    "    df = df.T\n",
    "    df.columns = df.iloc[0]\n",
    "    head = df.iloc[0].values\n",
    "    df = df.iloc[6:]\n",
    "    df.drop(df.index[-1],inplace=True)\n",
    "    df = df.set_index('N Sens', drop = True)\n",
    "    times = [datetime.strptime(time, '%H.%M') for time in df.index]\n",
    "    datetimes = [t.replace(year = year, month= current_date.month, day= current_date.day) for t in times]\n",
    "    df.index = datetimes\n",
    "    try:\n",
    "        df.columns = ['hidro_level_m1','precip_acumu_sm','hidro_level_sm']\n",
    "    except ValueError:\n",
    "        df.columns = ['hidro_level_m1']\n",
    "        # record the odd case with only data of a single sensor\n",
    "        df_list_esm_err.append(df)\n",
    "        print(current_date, head)\n",
    "\n",
    "    df_list_esm.append(df)\n",
    "# concat all the files\n",
    "df_esm_all = pd.concat(df_list_esm)\n",
    "# convert the data to be numeric\n",
    "df_esm_all = df_esm_all.apply(lambda x: pd.to_numeric(x, errors='coerce') if x.dtype == \"object\" else x)\n",
    "# convert the values to approriate decimals\n",
    "df_esm_all['hidro_level_m1'] = df_esm_all['hidro_level_m1']/100\n",
    "df_esm_all['hidro_level_sm'] = df_esm_all['hidro_level_sm']/100\n",
    "df_esm_all['precip_acumu_sm'] = df_esm_all['precip_acumu_sm']/1000\n",
    "# aggregate data with a unit frequency of 3 hours, nan values will be excluded from the calculation\n",
    "# the precipitation is a constantly accumulative value, the aggregation method should be the difference of the max and min value\n",
    "df_esm_3h = df_esm_all.resample('180min').agg({'hidro_level_m1': 'mean', 'precip_acumu_sm': diff, 'hidro_level_sm':'mean'})\n",
    "df_esm_3h = df_esm_3h.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the ccs data and Esmeradals data from CAE together and output to the local .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_ccs, df_esm_3h, left_index=True, right_index=True, how='outer')\n",
    "merged_df.shape\n",
    "# shape of (time, 2759), where 2759 = 53*52 (# of pixels de Esm basin ) + 3 (# of sensors)\n",
    "start = str(merged_df.index[0].date())\n",
    "end  = str(merged_df.index[-1].date())\n",
    "merged_df.to_csv(f'merged_{start}_{end}.csv', compression= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>60</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>...</th>\n",
       "      <th>2576</th>\n",
       "      <th>2577</th>\n",
       "      <th>2627</th>\n",
       "      <th>2628</th>\n",
       "      <th>2629</th>\n",
       "      <th>2679</th>\n",
       "      <th>2680</th>\n",
       "      <th>hidro_level_m1</th>\n",
       "      <th>precip_acumu_sm</th>\n",
       "      <th>hidro_level_sm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 06:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-07 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.36</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.88</td>\n",
       "      <td>8.12</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08 06:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08 09:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.14</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14754 rows × 1101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      60  111  112  113  114  162  163  164  165  166  ...  \\\n",
       "2019-01-01 00:00:00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2019-01-01 03:00:00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2019-01-01 06:00:00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2019-01-01 09:00:00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2019-01-01 12:00:00  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2024-03-07 21:00:00  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "2024-03-08 00:00:00  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "2024-03-08 03:00:00  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "2024-03-08 06:00:00  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "2024-03-08 09:00:00  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "\n",
       "                     2576  2577  2627  2628  2629  2679  2680  hidro_level_m1  \\\n",
       "2019-01-01 00:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0             NaN   \n",
       "2019-01-01 03:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0             NaN   \n",
       "2019-01-01 06:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0             NaN   \n",
       "2019-01-01 09:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0             NaN   \n",
       "2019-01-01 12:00:00   0.0   0.0   0.0   0.0   0.0   0.0   0.0             NaN   \n",
       "...                   ...   ...   ...   ...   ...   ...   ...             ...   \n",
       "2024-03-07 21:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN            1.78   \n",
       "2024-03-08 00:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN            2.67   \n",
       "2024-03-08 03:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN            1.88   \n",
       "2024-03-08 06:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN            0.75   \n",
       "2024-03-08 09:00:00   NaN   NaN   NaN   NaN   NaN   NaN   NaN            1.39   \n",
       "\n",
       "                     precip_acumu_sm  hidro_level_sm  \n",
       "2019-01-01 00:00:00              NaN             NaN  \n",
       "2019-01-01 03:00:00              NaN             NaN  \n",
       "2019-01-01 06:00:00              NaN             NaN  \n",
       "2019-01-01 09:00:00              NaN             NaN  \n",
       "2019-01-01 12:00:00              NaN             NaN  \n",
       "...                              ...             ...  \n",
       "2024-03-07 21:00:00             0.07            6.02  \n",
       "2024-03-08 00:00:00             2.36            5.98  \n",
       "2024-03-08 03:00:00             8.12            6.03  \n",
       "2024-03-08 06:00:00             0.11            6.09  \n",
       "2024-03-08 09:00:00             0.14            6.22  \n",
       "\n",
       "[14754 rows x 1101 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
