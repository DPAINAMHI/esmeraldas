{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funct\n",
    "import importlib\n",
    "funct = importlib.reload(funct)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import IPython\n",
    "import netCDF4 as nc\n",
    "import  xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read historical CCS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "incomplete data of June, 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 3\n",
    "rela_path_base = \"Data\\Persian_CCS_201901_202403\\CCS_esmJSON_2024-03-08075032am_\"\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    "    )\n",
    "# Get the parent directory path\n",
    "parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "# Change the directory (optional)\n",
    "os.chdir(parent_dir)\n",
    "# Now, your current working directory is the parent folder.\n",
    "\n",
    "df_list = []\n",
    "first_iter = True\n",
    "for month in funct.iterate_months(2019, 1, 2024, 3):\n",
    "    rela_path = rela_path_base + month + \".nc\"\n",
    "    df = funct.create_time_series_dataframe(freq, rela_path)\n",
    "    if first_iter:\n",
    "        df = df.replace(-99,np.nan)\n",
    "        cols_after_drop = df.dropna(axis=1, how='any').columns\n",
    "        first_iter = False\n",
    "    df_dropped = df[[col for col in cols_after_drop]]\n",
    "    df_list.append(df_dropped)\n",
    "df_ccs = pd.concat(df_list)\n",
    "# orginal shape of the Esmeraldas basin is of size 53*52\n",
    "# New flat array of 1098 pixels, showing only the net pixels of this basin area "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and organize data from Esmeraldas station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-01 ['N Sens' '78652']\n",
      "2023-10-02 ['N Sens' '78652']\n",
      "2023-10-03 ['N Sens' '78652']\n",
      "2023-10-04 ['N Sens' '78652']\n",
      "2023-10-05 ['N Sens' '78652']\n",
      "2023-10-06 ['N Sens' '78652']\n",
      "2023-10-12 ['N Sens' '78652']\n",
      "2023-10-13 ['N Sens' '78652']\n",
      "2023-10-14 ['N Sens' '78652']\n",
      "2023-10-15 ['N Sens' '78652']\n",
      "2023-10-16 ['N Sens' '78652']\n",
      "2023-10-17 ['N Sens' '78652']\n",
      "2023-10-18 ['N Sens' '78652']\n",
      "2023-10-19 ['N Sens' '78652']\n",
      "2023-10-20 ['N Sens' '78652']\n",
      "2023-10-21 ['N Sens' '78652']\n",
      "2023-10-22 ['N Sens' '78652']\n",
      "2023-10-23 ['N Sens' '78652']\n",
      "2023-10-24 ['N Sens' '78652']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liang.yang\\AppData\\Local\\Temp\\ipykernel_9620\\97517442.py:62: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_esm_3h = df_esm_all.resample('3H').agg({'hidro_level_m1': 'mean', 'precip_acumu_sm': 'sum', 'hidro_level_sm':'mean'})\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "from funct import format_number_with_zeros\n",
    "import chardet\n",
    "import re\n",
    "\n",
    "# Define start and end dates (replace with your desired dates)\n",
    "start_date = date(2023, 9, 6)  # Adjust year, month, day as needed\n",
    "end_date = date(2024, 3, 8)  # Adjust year, month, day as needed\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]\n",
    "    )\n",
    "# Get the parent directory path\n",
    "parent_dir = os.path.dirname(os.path.dirname(current_dir))\n",
    "# Change the directory (optional)\n",
    "os.chdir(parent_dir)\n",
    "# Now, your current working directory is the parent folder.\n",
    "\n",
    "# Iterate through each day using a for loop and timedelta\n",
    "\n",
    "df_list_esm = []\n",
    "df_list_esm_err = []\n",
    "\n",
    "# iterate to read every .csv file and convert them into transposed dataframe to align with the form of ccs data\n",
    "for day in range((end_date - start_date).days + 1):\n",
    "    current_date = start_date + timedelta(days=day)\n",
    "    # Do something with the current_date here (e.g., print, process data)\n",
    "    year = current_date.year\n",
    "    month = format_number_with_zeros(current_date.month,2)\n",
    "    day = format_number_with_zeros(current_date.day,2)\n",
    "    csv_path = \"Data\\Esm_Station\\yd\" + str(year) + \"\\md\" + str(year) + str(month) + \"\\\\\" + str(year) + str(month) + str(day) + \"_dvd.csv\"\n",
    "    with open(csv_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding']\n",
    "    df = pd.read_csv(csv_path, encoding= encoding, header = None ,skiprows=2)\n",
    "    df = df[0].apply(lambda x: pd.Series(re.split(';', x)))\n",
    "    df = df.T\n",
    "    df.columns = df.iloc[0]\n",
    "    head = df.iloc[0].values\n",
    "    df = df.iloc[6:]\n",
    "    df.drop(df.index[-1],inplace=True)\n",
    "    df = df.set_index('N Sens', drop = True)\n",
    "    times = [datetime.strptime(time, '%H.%M') for time in df.index]\n",
    "    datetimes = [t.replace(year = year, month= current_date.month, day= current_date.day) for t in times]\n",
    "    df.index = datetimes\n",
    "    try:\n",
    "        df.columns = ['hidro_level_m1','precip_acumu_sm','hidro_level_sm']\n",
    "    except ValueError:\n",
    "        df.columns = ['hidro_level_m1']\n",
    "        # record the odd case with only data of a single sensor\n",
    "        df_list_esm_err.append(df)\n",
    "        print(current_date, head)\n",
    "\n",
    "    df_list_esm.append(df)\n",
    "# concat all the files\n",
    "df_esm_all = pd.concat(df_list_esm)\n",
    "# convert the data to be numeric\n",
    "df_esm_all = df_esm_all.apply(lambda x: pd.to_numeric(x, errors='coerce') if x.dtype == \"object\" else x)\n",
    "# aggregate data with a unit frequency of 3 hours, nan values will be excluded from the calculation\n",
    "df_esm_3h = df_esm_all.resample('3h').agg({'hidro_level_m1': 'mean', 'precip_acumu_sm': 'sum', 'hidro_level_sm':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the ccs data and Esmeradals data from CAE together and output to the local .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14754, 1101)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df_ccs, df_esm_3h, left_index=True, right_index=True, how='outer')\n",
    "merged_df.shape\n",
    "# shape of (time, 2759), where 2759 = 53*52 (# of pixels de Esm basin ) + 3 (# of sensors)\n",
    "start = str(merged_df.index[0].date())\n",
    "end  = str(merged_df.index[-1].date())\n",
    "merged_df.to_csv(f'merged_{start}_{end}.csv', compression= None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
